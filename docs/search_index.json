[["index.html", "Introductory Bioinformatics for VAI Users Part 1 Introduction", " Introductory Bioinformatics for VAI Users The Bioinformatics and Biostatistics Core (BBC) Part 1 Introduction This book is divided into three sections: Basic command-line commands on the High-Performance Computing System (HPC). Performing a simple RNA-Seq analysis from read alignment to the identification of differentially expressed genes (DEGs). TBD "],["basic-command-line-utilities-on-the-hpc.html", "Part 2 Basic Command Line Utilities on the HPC 2.1 Access HPC 2.2 File navigation 2.3 View and manipulate files 2.4 Exercise 2.5 Summary", " Part 2 Basic Command Line Utilities on the HPC 2.1 Access HPC Ensure that your laptop is connected to wifi “vai”, not “vai-guest”. archived content: previous ssh connection instructions Note: The platform-specific instructions below are hidden by default because of the newer HPC OnDemand platform, which we can all access from our laptops using a web browser. However, for archival purposes, we will still provide the platform-specific instructions to access the HPC on your laptop. 2.1.0.1 Mac users Open your terminal (search for the app) Type the following command to connect to the HPC. Replace firstname.lastname with your actual VAI username. ssh firstname.lastname@access.hpc.vai.org Enter your VAI password. (Note: you will not see the password as you type it, but it is working! Press your enter/return key when you’re done.) 2.1.0.2 Windows users If MobaXterm is not installed, please download the free MobaXterm version, then set up, and agree with license agreements to proceed installation. Open MobaXterm Click on Session in the top left corner Click on SSH(Secure Shell) Enter access.hpc.vai.org in the Remote host field Click the box on the left of Specify username, then enter your VAI username and password Click OK 2.1.1 OnDemand Instructions OnDemand is a web-based portal that lets you access the HPC resources right from your browser, without needing VPN or ssh tools on your local computer. You can read more about this on the HPC OnDemand sharepoint page. Below are the steps to access the HPC command line using OnDemand: Open a web browser (Chrome, Firefox, Safari, etc.) Go to the following URL: https://ondemand3.vai.zone/ if you see an error, try this instead: https://ondemandlocal.hpc.vai.org if neither or those links work, please let us know! Select “hpc Shell Access” from the list of several “pinned apps”. (“hpc Shell Access” is similar to the terminal on your laptop) Congrats – you’ve successfully connected to the HPC! 2.2 File navigation Practice directory: /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II. 2.2.1 Navigate to a directory (folder) cd - Change Directory. Allows you to navigate to a different directory (folder). Note the following special symbols: . refers to the folder you’re currently in (your “working” directory). .. refers to the folder before where you currently are - this is your “parent” directory. / is the root directory. ~ is your personal home directory. pwd - Print Working Directory. Displays the current directory (folder) you are in. # Display the current directory pwd # Change to the practice directory cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II # Display the current directory again to confirm the change pwd ## /home/kaitlyn.denhaan ## /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II 2.2.2 List content in a directory ls - list contents (files and folders). Without anything specified after ls, it will list what’s in the current directory. ls -lht – list contents, with added options (-l more details in a long list, -h human-readable sizes, -t sorted by modification time). ls foldername - list contents of the specified folder. Shows more details about the files and folders, ls ls -lht ls -lht /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II ls -lht ~ 2.2.3 Navigate back to home directory Without anything after cd, you will go to your home directory, which is /home/username (same as ~). # same as &quot;cd ~&quot; or &quot;cd /home/username&quot; cd # check: where are you now? pwd 2.2.4 Create a directory mkdir dir_name - will create a directory “dir_name” in your current directory. You will be creating a directory in your home drectory (because we just navigated to it). Make sure you are in your home directory first (use pwd), then create a directory called “hpc_workshop_2024” pwd mkdir hpc_workshop_2024 2.2.5 Copy a file cp - copy file/files Copy a file from /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II to the directory you just created. pwd cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/metadata.tsv hpc_workshop_2024 ls hpc_workshop_2024 2.3 View and manipulate files 2.3.1 Display content cat - display the entire contents of a file. head - display the first 10 lines/rows of the a file. tail - display the last 10 lines/rows of the a file. You can use “-n” to control how many lines you want to see, default is 10. cd ~/hpc_workshop_2024 cat metadata.tsv head metadata.tsv tail metadata.tsv head -n 2 metadata.tsv The cat command can also be used to combine files. (This is where the command’s name comes from: concatenate) Note that we won’t run the command below, but keep this in mind for future reference. cat file1.txt file2.txt &gt; combined.txt 2.3.2 Pattern search grep - search a pattern by line pwd grep &quot;13&quot; metadata.tsv ## /home/kaitlyn.denhaan/hpc_workshop_2024 ## M 13 sample 13 replicate a ## Z 26 sample 13 replicate b 2.3.3 Display the number of lines, words, and characters wc - word count. It counts the number of lines, words, and characters in a file. Adding the -l option afterwards just gives the number of lines in the file. wc metadata.tsv wc -l metadata.tsv ## 26 156 675 metadata.tsv ## 26 metadata.tsv 2.3.4 Pipe - redirection A pipe is a form of redirection (instead of printing output to the screen, it sends it to other destinations). You can send output from one command/program to another for further processing, such as: command 1 | command 2 | command 3. Above, the output from command 1 is used as input for command 2, and the output from command 2 is used as input for command 3. In the example below, we will use 3 commands subsequently to count the number of lines that contain the number “13” in the file. cat metadata.tsv | grep &quot;13&quot; | wc -l ## 2 2.3.5 Output redirection Instead of printing output to your screen (typical command output) or another command (pipe), you can redirect the output to a file. &gt; - redirect output to a file. Note that it will overwrite the file if it already exists – be careful! &gt;&gt; - append output to a file. It will add the output to the end of the file. # note that no output will be displayed on the screen -- it&#39;s saved in the file instead grep &quot;13&quot; metadata.tsv &gt; lines_with_13.tsv # check: do we see the file we just created? ls # display the content of the file cat lines_with_13.tsv ## data_01_R1.fq ## data_54_R1.fq ## lines_with_13.tsv ## metadata.tsv ## M 13 sample 13 replicate a ## Z 26 sample 13 replicate b 2.4 Exercise Below, we’ll be doing something similar to the exercises above, but with real genomic data! We’ll be using a fastq file (format containing raw sequencing &amp; quality information). We will: copy fastq files from the practice directory to the folder you created combine the two fastq files into one count the number of reads in the combined file See if you can do each step on your own – if you get stuck, don’t worry! Try to remember the commands we’ve learned so far, and you can always refer back to the examples above. To check your work, you can view the commands below. 2.4.1 Step 1: Copy the files Once you’re in your hpc_workshop_2024 directory, copy the files data_01_R1.fq and data_54_R1.fq from the practice directory (/varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II) into your folder. Click here to see a solution cd ~/hpc_workshop_2024 cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/data_01_R1.fq . cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/data_54_R1.fq . 2.4.2 Step 2: Combine the files Combine the two fastq files into one file called combined.fq. Click here to see a solution cat data_01_R1.fq data_54_R1.fq &gt; combined.fq ls ## combined.fq ## data_01_R1.fq ## data_54_R1.fq ## lines_with_13.tsv ## metadata.tsv 2.4.3 Step 3: Count the number of reads Count the number of reads in the combined file. Hint #1 – what is a “read”? In a fastq file, reads start with the “@” symbol. Hint #2 – how to approach this? See if you can combine a few commands together! Plan out each of the steps you need to do, then put them all together. Click here to see an example solution # use that combined file grep &quot;@&quot; combined.fq | wc -l # a different way to do the same thing cat combined.fq | grep &quot;@&quot; | wc -l # or, combine the commands all together cat data_01_R1.fq data_54_R1.fq | grep &quot;@&quot; | wc -l ## 500 ## 500 ## 500 Can you explain why your solution works? Which solution above does yours look most similar to? Congratulations! You’ve successfully completed the exercise. BONUS: If you have extra time, use the skills you’ve learned to explore the fastq file format further: Count the total number of lines in the combined file. Using your answer from the exercise above (count the number of reads) – how are the number of reads related to the total number of lines in the file? Look at some of the contents of the combined fastq file. What do you notice about the structure of the file? Can you find any patterns? What do you think each line represents? What are some questions you have about the fastq file format? 2.5 Summary In this section, we’ve covered the basic commands for navigating directories, viewing and manipulating files, using pipes, and redirecting output. You’ve learned how to: Navigate to a directory List content in a directory Create a directory Copy a file Display content Search for patterns Display the number of words, lines, and characters Use pipes for redirection Use output redirection These are the fundamental commands you’ll need to work with files and directories on the HPC. In the next section, we’ll work through a real bioinformatics “mini-project” that builds on these commands, so you can see how they can be used together to solve a problem. Next: Bioinformatics Mini Project "],["mini-project.html", "Part 3 Mini Project 3.1 Start an Interactive Job 3.2 Create Directory 3.3 Copy Fastq Files To fastqs subdirectory 3.4 Use basic Linux commands to explore the fastq files 3.5 Working With Environment Modules 3.6 Run FastQC 3.7 Set up a job script to run Salmon to align the reads 3.8 Submit a Job 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files 3.10 Use grep to find the TPMs for a specific gene 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output", " Part 3 Mini Project Here, we will combine some of the commands we have learned today to perform a toy bioinformatic analysis. Two human paired-end samples (four total fastq files) have already been downloaded from GSE52778 and are in the directory /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs. To save time for the workshop, each file has been randomly subsetted to just a small fraction of the total reads. Here each user will: Copy these fastq files their own private project directory. Use basic Linux commands to learn some characteristics of these files. Use Salmon to align (pseudo-align) these reads to the hg38 reference transcriptome and get transcripts-per-million (TPMs) for each annotated gene. 3.1 Start an Interactive Job While simple file manipulations can be done on the submit node, computationally intensive operations should be performed using preallocated computational resources. An interactive job allows us to preallocate resources while still being able to run commands line by line. We will start an interactive job, requesting one CPU core and 1 hour and 30 minutes of walltime. srun -p quick --nodes=1 --ntasks-per-node=1 --time=01:30:00 --pty bash After a job has been submitted, users can check on the status (e.g. how long it has been running) of it using the following. squeue --me 3.2 Create Directory Typically, one would work in their specific lab’s folder on the HPC. For this workshop, we will work in a common directory so that the instructors and check on your progress. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/ Create a directory based on your username to separate your work from other users’. mkdir &lt;username&gt; Navigate to the username directory cd &lt;username&gt; Create a fastqs directory inside the username directory. It is good practice to keep your raw data separate from your analyses and never make changes to them directly. mkdir fastqs Use ls to confirm the fastqs directory was created. ls 3.3 Copy Fastq Files To fastqs subdirectory Verify the current directory is in the username directory. pwd Copy the 4 fastq.gz files and md5sum.txt, which you will use to check the validty of the files. cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs/*fastq.gz ./fastqs/ cp /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/fastqs/md5sum.txt ./fastqs/ Verify that the copied files are valid. The following code should return with an OK for each file. cd fastqs md5sum -c md5sum.txt ## SRR1039520_1.fastq.gz: OK ## SRR1039520_2.fastq.gz: OK ## SRR1039521_1.fastq.gz: OK ## SRR1039521_2.fastq.gz: OK Go back to the username directory. cd .. 3.4 Use basic Linux commands to explore the fastq files Notice all of the sequence data files end with a .gz extension, indicating they are gzip compressed. To view such files, one must use zcat instead of cat so that the files are decompressed into human-readable format. zcat fastqs/SRR1039520_1.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## CCAGGACATCAAGAAGCCAGCTGAAGATGAGTGGGGTAAAACCCCAGACGCCATGAAAGCTGC ## + ## HJJJJJJJJJJJJJJJIJJJJJJJJIJJJJJGGJJJFHIJIIJJIGHHFFFDDDDDCDDDCDD ## @SRR1039520.3404519 3404519 length=63 ## TGAGACATGGTTATAGATAAGAGAGTACAAAATGACTCTTTTTCCTGTCAATTGAAATTTAAA ## + ## HIGDFBGIIJBHGIIEHIIJIJIIIEGGIIIHGIJJIJJJIIJGIIIIGIEHIGDCHHIICG7 ## @SRR1039520.16253787 16253787 length=63 ## CAGGAGACCAAAGACACTGCAATTTGTGTGTTTTCTACAGGGTGCTTTAGATGACGTCTCATT zcat fastqs/SRR1039520_2.fastq.gz | head ## @SRR1039520.19151550 19151550 length=63 ## GAGATGGGGGTCCGTGCGGGCAGAACCCAGGGCATGAAGATCCAAAAGGGCCTGGTTCAGCTT ## + ## HJJJJJJJJJHHHIGIJIJJJJJJJHHHHFFFDDEEDDDDDDDDDDDDDDDDDDDDDDDDDDD ## @SRR1039520.3404519 3404519 length=63 ## TTTGACCCTAGTATTGGCAATAGCCCTTTGCTATTTATATAATTAAAACTTTTCTTTAAATTT ## + ## HIJIJJJJIIEHGIGIIIDGIJJJJIIJJJIJJJIJJJIIIJJJJIJJGCHIJJJJJIJIJII ## @SRR1039520.16253787 16253787 length=63 ## TACAGTTTGCAAAAGATGTCCAGATGGGTTCTTCTCAAATGAGACGTCATCTAAAGCACCCTG Notice that SRR1039520_1.fastq.gz and SRR1039520_2.fastq.gz files have the same read IDs. Valid paired fastq files always have matching read IDs throughout the entire file. Next, we can figure out how many reads are in a fastq file using wc -l. Recall that each read is represented by 4 lines in a fastq file, so we need to divide the results of wc -l by 4 to get the number of reads. zcat fastqs/SRR1039520_1.fastq.gz | wc -l ## 2000000 Finally, we can use wc -m to figure out the read length in a fastq file. Below, we use a combination of head -n2 and tail -n1 to get the second line of the first read. You may notice that the results of wc -m will be 1 higher than the actual read length. This is because the tool counts the newline character also. zcat fastqs/SRR1039520_1.fastq.gz | head -n2 | tail -n1 | wc -m ## 64 3.5 Working With Environment Modules Type module av bbc2 (modules beginning with just bbc are from the old HPC) to see all the software installed by the BBC. There are a lot of modules installed; to parse through these more easily, we can pipe the results of module av into grep to search for modules with specific keywords. There is a trick, though. The results of module av go to standard error, so we need to redirect standard error to standard out using 2&gt;&amp;1 before the pipe. This command will output any modules containing the fastqc keyword. module av -w 1 bbc2 2&gt;&amp;1 | grep &#39;fastqc&#39; ## bbc2/fastqc/fastqc-0.12.1 3.6 Run FastQC Create a fastqc directory inside of your username directory and run FastQC. module load bbc2/fastqc/fastqc-0.12.1 mkdir fastqc # Run FastQC. You can also run `fastqc -h` to see what different options do. fastqc -o fastqc fastqs/*fastq.gz ## Loading bbc2/fastqc/fastqc-0.12.1 ## Loading requirement: VARI/java/1.8.0_202 ## mkdir: cannot create directory ‘fastqc’: File exists ## application/gzip ## application/gzip ## Started analysis of SRR1039520_1.fastq.gz ## application/gzip ## application/gzip ## Approx 5% complete for SRR1039520_1.fastq.gz ## Approx 10% complete for SRR1039520_1.fastq.gz ## Approx 15% complete for SRR1039520_1.fastq.gz ## Approx 20% complete for SRR1039520_1.fastq.gz ## Approx 25% complete for SRR1039520_1.fastq.gz ## Approx 30% complete for SRR1039520_1.fastq.gz ## Approx 35% complete for SRR1039520_1.fastq.gz ## Approx 40% complete for SRR1039520_1.fastq.gz ## Approx 45% complete for SRR1039520_1.fastq.gz ## Approx 50% complete for SRR1039520_1.fastq.gz ## Approx 55% complete for SRR1039520_1.fastq.gz ## Approx 60% complete for SRR1039520_1.fastq.gz ## Approx 65% complete for SRR1039520_1.fastq.gz ## Approx 70% complete for SRR1039520_1.fastq.gz ## Approx 75% complete for SRR1039520_1.fastq.gz ## Approx 80% complete for SRR1039520_1.fastq.gz ## Approx 85% complete for SRR1039520_1.fastq.gz ## Approx 90% complete for SRR1039520_1.fastq.gz ## Approx 95% complete for SRR1039520_1.fastq.gz ## Approx 100% complete for SRR1039520_1.fastq.gz ## Analysis complete for SRR1039520_1.fastq.gz ## Started analysis of SRR1039520_2.fastq.gz ## Approx 5% complete for SRR1039520_2.fastq.gz ## Approx 10% complete for SRR1039520_2.fastq.gz ## Approx 15% complete for SRR1039520_2.fastq.gz ## Approx 20% complete for SRR1039520_2.fastq.gz ## Approx 25% complete for SRR1039520_2.fastq.gz ## Approx 30% complete for SRR1039520_2.fastq.gz ## Approx 35% complete for SRR1039520_2.fastq.gz ## Approx 40% complete for SRR1039520_2.fastq.gz ## Approx 45% complete for SRR1039520_2.fastq.gz ## Approx 50% complete for SRR1039520_2.fastq.gz ## Approx 55% complete for SRR1039520_2.fastq.gz ## Approx 60% complete for SRR1039520_2.fastq.gz ## Approx 65% complete for SRR1039520_2.fastq.gz ## Approx 70% complete for SRR1039520_2.fastq.gz ## Approx 75% complete for SRR1039520_2.fastq.gz ## Approx 80% complete for SRR1039520_2.fastq.gz ## Approx 85% complete for SRR1039520_2.fastq.gz ## Approx 90% complete for SRR1039520_2.fastq.gz ## Approx 95% complete for SRR1039520_2.fastq.gz ## Approx 100% complete for SRR1039520_2.fastq.gz ## Analysis complete for SRR1039520_2.fastq.gz ## Started analysis of SRR1039521_1.fastq.gz ## Approx 5% complete for SRR1039521_1.fastq.gz ## Approx 10% complete for SRR1039521_1.fastq.gz ## Approx 15% complete for SRR1039521_1.fastq.gz ## Approx 20% complete for SRR1039521_1.fastq.gz ## Approx 25% complete for SRR1039521_1.fastq.gz ## Approx 30% complete for SRR1039521_1.fastq.gz ## Approx 35% complete for SRR1039521_1.fastq.gz ## Approx 40% complete for SRR1039521_1.fastq.gz ## Approx 45% complete for SRR1039521_1.fastq.gz ## Approx 50% complete for SRR1039521_1.fastq.gz ## Approx 55% complete for SRR1039521_1.fastq.gz ## Approx 60% complete for SRR1039521_1.fastq.gz ## Approx 65% complete for SRR1039521_1.fastq.gz ## Approx 70% complete for SRR1039521_1.fastq.gz ## Approx 75% complete for SRR1039521_1.fastq.gz ## Approx 80% complete for SRR1039521_1.fastq.gz ## Approx 85% complete for SRR1039521_1.fastq.gz ## Approx 90% complete for SRR1039521_1.fastq.gz ## Approx 95% complete for SRR1039521_1.fastq.gz ## Approx 100% complete for SRR1039521_1.fastq.gz ## Analysis complete for SRR1039521_1.fastq.gz ## Started analysis of SRR1039521_2.fastq.gz ## Approx 5% complete for SRR1039521_2.fastq.gz ## Approx 10% complete for SRR1039521_2.fastq.gz ## Approx 15% complete for SRR1039521_2.fastq.gz ## Approx 20% complete for SRR1039521_2.fastq.gz ## Approx 25% complete for SRR1039521_2.fastq.gz ## Approx 30% complete for SRR1039521_2.fastq.gz ## Approx 35% complete for SRR1039521_2.fastq.gz ## Approx 40% complete for SRR1039521_2.fastq.gz ## Approx 45% complete for SRR1039521_2.fastq.gz ## Approx 50% complete for SRR1039521_2.fastq.gz ## Approx 55% complete for SRR1039521_2.fastq.gz ## Approx 60% complete for SRR1039521_2.fastq.gz ## Approx 65% complete for SRR1039521_2.fastq.gz ## Approx 70% complete for SRR1039521_2.fastq.gz ## Approx 75% complete for SRR1039521_2.fastq.gz ## Approx 80% complete for SRR1039521_2.fastq.gz ## Approx 85% complete for SRR1039521_2.fastq.gz ## Approx 90% complete for SRR1039521_2.fastq.gz ## Approx 95% complete for SRR1039521_2.fastq.gz ## Approx 100% complete for SRR1039521_2.fastq.gz ## Analysis complete for SRR1039521_2.fastq.gz See what was produced by FastQC. ls fastqc/ ## SRR1039520_1_fastqc.html ## SRR1039520_1_fastqc.zip ## SRR1039520_2_fastqc.html ## SRR1039520_2_fastqc.zip ## SRR1039521_1_fastqc.html ## SRR1039521_1_fastqc.zip ## SRR1039521_2_fastqc.html ## SRR1039521_2_fastqc.zip 3.7 Set up a job script to run Salmon to align the reads First, we exit from our interactive job because we want to get back on to the submit node to submit a non-interactive job to run Salmon. # You should see one job when you run this command, corresponding to your interactive job. squeue --me # Exit the interactive job exit # Now you should see no jobs when you run this command because the interactive job has ended. squeue --me # Go back to your project directory cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/&lt;username&gt; Below is a SLURM job script to run Salmon. For now, do not worry about how the code works. Copy the code and paste it into a new file. Save it as run_salmon.sh in your username directory. If you have issues with this task, you can copy the job script directly using the command, cp /varidata/researchtemp/hpctmp/BBC_workshop_June2023/kin.lau/run_salmon.sh .. #!/bin/bash #SBATCH --export=NONE #SBATCH -J run_salmon #SBATCH -o run_salmon.o #SBATCH -e run_salmon.e #SBATCH --ntasks 4 #SBATCH --time 1:00:00 #SBATCH --mem=31G start_time=$(date +&quot;%T&quot;) # You need to navigate to your project directory. Conveniently, the $SLURM_SUBMIT_DIR variable stores the path for where the job was submitted. cd ${SLURM_SUBMIT_DIR} module load bbc2/salmon/salmon-1.10.0 # Typically, you would have to first build an index before doing the aligning, but we have done this for you already. Here, we store the path to the index file in a variable called &#39;salmon_idx&#39;. salmon_idx=&quot;/varidata/research/projects/bbc/versioned_references/2022-03-08_14.47.50_v9/data/hg38_gencode/indexes/salmon/hg38_gencode/&quot; # make output directory for salmon mkdir -p salmon # This is called a for loop. We use this to run salmon quant on all the samples, one at a time. It is more efficient to run salmon on each sample &quot;in parallel&quot; but we will not do that today. for samp_id in SRR1039520 SRR1039521 do salmon quant -p ${SLURM_NTASKS} -l A -i $salmon_idx -1 fastqs/${samp_id}_1.fastq.gz -2 fastqs/${samp_id}_2.fastq.gz -o salmon/${samp_id} --validateMappings done end_time=$(date +&quot;%T&quot;) echo &quot;Start time: $start_time&quot; echo &quot;End time: $end_time&quot; 3.8 Submit a Job Type ls to ensure run_salmon.sh file exist in the username directory. ls Use the sbatch command to submit the job. sbatch -p quick run_salmon.sh Users can check if the job is running with the following command. The job should take about two minutes to complete. squeue --me 3.9 Examine the Standard Output (stdout) and Standard Error (stderr) log files It is good practice to check the job logs after your job is done to ensure that the job completed successfully. If there is an error, the output files may not be reliable or could be incomplete. tail run_salmon.e ## [2023-06-07 22:33:35.747] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate ## [2023-06-07 22:33:35.775] [jointLog] [info] iteration = 0 | max rel diff. = 202.323 ## [2023-06-07 22:33:38.554] [jointLog] [info] iteration = 100 | max rel diff. = 6.56983 ## [2023-06-07 22:33:41.286] [jointLog] [info] iteration = 200 | max rel diff. = 0.770961 ## [2023-06-07 22:33:44.016] [jointLog] [info] iteration = 300 | max rel diff. = 5.57356 ## [2023-06-07 22:33:46.748] [jointLog] [info] iteration = 400 | max rel diff. = 0.0347411 ## [2023-06-07 22:33:48.577] [jointLog] [info] iteration = 468 | max rel diff. = 0.00847769 ## [2023-06-07 22:33:48.619] [jointLog] [info] Finished optimizer ## [2023-06-07 22:33:48.619] [jointLog] [info] writing output tail run_salmon.o ## Start time: 22:32:29 ## End time: 22:33:50 3.10 Use grep to find the TPMs for a specific gene As an example, let’s try to extract out the TPMs (Transcripts per Million) for MUC1. These values can be found in the quant.sf file in each sample’s folder. First, let’s take a look at one of these files to figure out the format of these files. head salmon/SRR1039520/quant.sf ## Name Length EffectiveLength TPM NumReads ## ENST00000456328.2 1657 1502.026 0.000000 0.000 ## ENST00000450305.2 632 477.161 0.000000 0.000 ## ENST00000488147.1 1351 1196.026 0.000000 0.000 ## ENST00000619216.1 68 1.953 0.000000 0.000 ## ENST00000473358.1 712 557.109 0.000000 0.000 ## ENST00000469289.1 535 380.280 0.000000 0.000 ## ENST00000607096.1 138 24.930 0.000000 0.000 ## ENST00000417324.1 1187 1032.026 0.000000 0.000 ## ENST00000461467.1 590 435.202 0.000000 0.000 From the output above, we can see that the TPMs are in the 4th column of this file. The canonical transcript for MUC1 is ENST00000620103, so we will search for that using grep. grep &#39;ENST00000620103&#39; salmon/SRR1039520/quant.sf ## ENST00000620103.4 1811 1656.026 0.000000 0.000 Look for MUC1 across all the samples at the same time. We can see that ‘SRR1039521’ has a TPM of 13.1 for MUC1 compared to 0 for ‘SRR1039520’. Recall that the fastq files for this exercise were subsetted to a very small number of reads so don’t interpret these results seriously. grep &#39;ENST00000620103&#39; salmon/*/quant.sf ## salmon/SRR1039520/quant.sf:ENST00000620103.4 1811 1656.026 0.000000 0.000 ## salmon/SRR1039521/quant.sf:ENST00000620103.4 1811 1655.632 13.165700 5.728 3.11 BONUS: Use an interactive job to run multiQC on the Salmon and FastQC output In this final step, users will start an interactive job to perform multiQC to collect and summarize the outcomes from FastQC and Salmon, then evaluate the quality of the fastq sequences with the reference transcriptome(mapping rate). Start an interactive job. srun --nodes=1 --ntasks-per-node=1 --time=00:30:00 --pty bash Navigate to the project directory. cd /varidata/researchtemp/hpctmp/BBC_workshop_Oct2024_II/&lt;username&gt; Load the environment module for multiQC. module load bbc2/multiqc/multiqc-1.14 ## ## ### Loaded BBC module ## Loading this module prepends to $PYTHONPATH ## Don&#39;t use with conda. ## ### End BBC module message. Run multiQC, which will summarize the results from FastQC and Salmon and output the results into a new directory called multiqc/. multiqc --outdir multiqc . List the contents of the multiqc directory. ls multiqc ## multiqc_data ## multiqc_report.html Note the newly created multiqc_report.html file. Try to view this file in your preferred internet browser. If you have mounted the HPC file system to your computer, you can simply double-click on this file. Alternatively, you can copy this file to your computer’s local storage first and then open it. "],["basic-rna-seq-analysis-from-fastq-files-to-de-genes.html", "Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.2 Quality control 4.3 Exploring the data using iSEE 4.4 DE analysis using R and DESeq2 4.5 Some common plots for DEG analysis", " Part 4 Basic RNA-Seq Analysis – From fastq files to DE genes 4.1 Run the BBC pipeline to align the reads 4.1.1 The workflow as a graph The workflow. 4.1.2 Clone the Github repo Instructions for running it are on the Github README, but here we will go through each step in more detail. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023_II/ mkdir &lt;username&gt; cd &lt;username&gt; git clone https://github.com/vari-bbc/rnaseq_workflow.git The Github repository consisting of the RNA-seq workflow should now be downloaded in a folder named rnaseq_workflow. cd rnaseq_workflow ls 4.1.3 Add your fastq files to raw_data/ Instead of making multiple copies of the same file, which can quickly use up your lab’s storage quota, we can use symbolic links. The sequence data that we will be using for this workshop are from the airway dataset referenced in the DESeq2 vignette. The gene counts can actually be downloaded as an R package. ls ../../0_fastqs/ ln -sr ../../0_fastqs/* ./raw_data You can see where the symbolic links are pointing to using ls -l. ls -l ./raw_data 4.1.4 Fill out the samplesheet The samplesheet is a tab-delimited file within config/samplesheet/ and is named units.tsv. The easiest way to fill this out is to run the helper script, make_units_template.sh, to generate a template, then edit using a text editor. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE. cd config/samplesheet/ ./make_units_template.sh There should now be a file named ‘units_template.tsv’. ls We can replace the ‘units.tsv’ with ‘units_template.tsv’. mv units_template.tsv units.tsv Go back to the base level of the project directory. cd ../.. Make sure you are at /varidata/researchtemp/hpctmp/BBC_workshop_June2023_II/&lt;username&gt;/rnaseq_workflow. pwd 4.1.5 Fill out the config file The config file is a YAML file indicating the locations of reference files and also contains options for the workflow that you can turn off or turn on. Typically, the main thing is to specify reference files corresponding to the species you have sequenced (human, mouse, or rat etc). For this workshop, we are dealing with human data so we will align to the hg38 reference. Index files allow alignment algorithms to align reads to specific reference sequences. FOR THIS WORKSHOP, NO CHANGES NEED TO BE MADE. cat config/config.yaml 4.1.6 Submit the main Snakemake job sbatch -p big bin/run_snake.sh 4.1.7 BBC-maintained reference files For future reference, the BBC downloads and maintains commonly used files and indexes for several model species. These files are version controlled to promote reproducibility in case you need to rerun an analysis or you want to run the exact same analysis on different datasets. ls /varidata/research/projects/bbc/versioned_references/ ## 2021-04-09_12.44.55_v1 ## 2021-07-02_11.23.48_v3 ## 2021-07-13_09.57.31_v4 ## 2021-08-02_20.40.24_v5 ## 2021-08-10_11.12.27_v6 ## 2021-10-25_15.31.38_v7 ## 2022-01-26_13.39.07_v8 ## 2022-03-08_14.47.50_v9 ## 2022-10-06_14.25.40_v10 ## 2022-12-19_13.27.04_v11 ## 2023-05-03_15.28.41_v12 ## 2023-10-04_10.07.51_v13 ## 2023-10-06_11.13.48_v14 ## 2023-11-08_15.45.32_v15 ## 2023-11-09_09.38.05_v16 ## latest ## regarding_v2.txt ls /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/data/ ## GRCz11 ## c.elegans-WBcel235 ## dm6_BDGP6.28.100 ## e.coli-K12-mg1665_ensembl ## hg19_gencode ## hg19_gencode_plus_ERCC92 ## hg19_gencode_plus_viruses ## hg38_gencode ## mm10_gencode ## mm10_gencode_plus_ERCC92 ## mm10_gencode_plus_e.coli-K12-mg1665_ensembl ## mm10_gencode_plus_viruses_and_cfmedips ## mm11_gencode ## mm9_ucsc ## mm_BALB_CJ ## mm_BALB_CJ_plus_viruses_and_cfmedips ## mm_FVB_NJ ## mm_FVB_NJ_plus_viruses_and_cfmedips ## rnor6_ensembl The source of these files can be found in the species.tsv file. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/species.tsv | cut -f2-3 ## id genome_fasta ## mm10_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M24/GRCm38.primary_assembly.genome.fa.gz ## hg38_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/GRCh38.primary_assembly.genome.fa.gz ## e.coli-K12-mg1665_ensembl ftp://ftp.ensemblgenomes.org/pub/release-47/bacteria//fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.dna.chromosome.Chromosome.fa.gz ## hg19_gencode ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_36/GRCh37_mapping/GRCh37.primary_assembly.genome.fa.gz ## dm6_BDGP6.28.100 ftp://ftp.ensembl.org/pub/release-100/fasta/drosophila_melanogaster/dna/Drosophila_melanogaster.BDGP6.28.dna.toplevel.fa.gz ## c.elegans-WBcel235 http://ftp.ensembl.org/pub/release-103/fasta/caenorhabditis_elegans/dna/Caenorhabditis_elegans.WBcel235.dna.toplevel.fa.gz ## mm_BALB_CJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_balbcj/dna/Mus_musculus_balbcj.BALB_cJ_v1.dna.toplevel.fa.gz ## mm_FVB_NJ http://ftp.ensembl.org/pub/release-104/fasta/mus_musculus_fvbnj/dna/Mus_musculus_fvbnj.FVB_NJ_v1.dna.toplevel.fa.gz ## rnor6_ensembl http://ftp.ensembl.org/pub/release-104/fasta/rattus_norvegicus/dna/Rattus_norvegicus.Rnor_6.0.dna.toplevel.fa.gz ## GRCz11 https://ftp.ensembl.org/pub/release-108/fasta/danio_rerio/dna/Danio_rerio.GRCz11.dna.toplevel.fa.gz ## mm11_gencode https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M31/GRCm39.primary_assembly.genome.fa.gz ## mm9_ucsc ftp://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/mm9.fa.gz The verions of the software used to generate the index files can be found in the config.yaml file. Sometimes index files are not backwards-compatible, meaning index files generated by a newer version of a tool cannot be used by an older version of the tool. cat /varidata/research/projects/bbc/versioned_references/2023-05-03_15.28.41_v12/bin/config.yaml ## # This is the directory that the rsync rule will use as the source directory. It shuold be the run directory this workflow. ## sourceDir: &quot;/varidata/research/projects/bbc/research/prep_bbc_shared_current&quot; ## ## # This is where the timestamped directories and the &#39;latest&#39; symlink will be created. ## timestamp_dir: &quot;/varidata/research/projects/bbc/versioned_references/&quot; ## ## # Environment modules used. ## # Specify all environment modules here instead of within the Snakefile itself to make it easy to look over quickly. ## # When aligning using the index files created by this workflow, use the same version aligner as listed here to ensure compatibility. ## samtools: &quot;bbc/samtools/samtools-1.9&quot; ## picard: &quot;bbc/picard/picard-2.21.4-SNAPSHOT&quot; ## STAR: &quot;bbc/STAR/STAR-2.7.8a&quot; ## biscuit: &quot;bbc/biscuit/biscuit_1_0_1&quot; ## bwa: &quot;bbc/bwa/bwa-0.7.17&quot; ## bowtie2: &quot;bbc/bowtie2/bowtie2-2.4.1&quot; ## python3: &quot;bbc/python3/python-3.8.1&quot; ## bismark: &quot;bbc/bismark/bismark-0.23.0&quot; ## kb-python: &quot;bbc/kb-python/kb-python-0.24.4&quot; ## parallel: &quot;bbc/parallel/parallel-20191122&quot; ## gsutil: &quot;bbc/gsutil/gsutil-4.52&quot; ## seqtk: &quot;bbc/seqtk/seqtk-1.3-r115-dirty&quot; ## salmon: &quot;bbc/salmon/salmon-1.4.0&quot; ## kallisto: &quot;bbc/kallisto/kallisto-0.46.1&quot; 4.2 Quality control It’s important to look through QC metrics to ensure that the data is likely to produce meaningful results. Ideally, you don’t want to waste time trying to interpret bad data. 4.2.1 multiQC report Navigate to your project folder using Finder (Mac) or File Explorer (Windows). Find results/multiqc/multiqc_report.html and double-click it. Alignment rate? Higher duplication rate can be normal for RNA-seq. Strandedness; In our workflow, this is automatically inferred using Salmon. Any contamination? Check FastqScreen results. 4.2.2 Other considerations Not a bad idea to look quickly at the alignments in IGV. Any sign of gDNA contamination? Mutations in specific genotypes? Is it exonic? Can do a quick check in IGV. How many genes expressed? Easy to check in R. Marker genes? Can do a quick check in iSEE if you expect certain expression patterns between groups. Any genes supposed to knocked out or knocked down? Use iSEE. Does the PCA show clustering? Use iSEE. 4.3 Exploring the data using iSEE Navigate to your project folder using Finder (Mac) or File Explorer (Windows). Find iSEE/app.R and double-click it. iSEE screenshot. 4.4 DE analysis using R and DESeq2 4.4.1 Make an output directory outdir &lt;- &quot;./deseq2_out_files/&quot; dir.create(outdir, recursive=TRUE) 4.4.2 Load packages suppressMessages(library(dplyr)) library(stringr) library(ggplot2) library(readr) library(ggrepel) suppressMessages(library(ComplexHeatmap)) suppressMessages(library(DESeq2)) 4.4.3 Set up your DESeq object se &lt;- readRDS(&quot;../results/SummarizedExperiment/SummarizedExperiment.rds&quot;) Let’s take a look to see what assays are stored in the SummarizedExperiment object. Note that DESeq2 assumes the first assay is the raw counts. assayNames(se) ## [1] &quot;counts&quot; &quot;tpms&quot; &quot;vst&quot; stopifnot(assayNames(se)[1] == &quot;counts&quot;) To print more information about this SummarizedExperiment object, you can just type its name. se ## class: SummarizedExperiment ## dim: 60721 8 ## metadata(0): ## assays(3): counts tpms vst ## rownames(60721): ENSG00000223972.5 ENSG00000227232.5 ... ## ENSG00000278625.1 ENSG00000277374.1 ## rowData names(4): Symbol Uniq_syms entrez Gene_name ## colnames(8): SRR1039509 SRR1039513 ... SRR1039516 SRR1039520 ## colData names(2): sample group The counts and the meta data need to be stored inside a special DESeq2 object called a ‘DESeqDataSet’. Here, we also specify that each gene will be fit with a model design of ‘~ group’. dds &lt;- DESeqDataSet(se, design = ~ group) ## converting counts to integer mode ## Warning in DESeqDataSet(se, design = ~group): some variables in design formula ## are characters, converting to factors 4.4.4 Remove genes with low/no expression We cannot do meaningful analyses of genes with very low counts. This will speed up the analysis. # prefilter genes, keeping only genes with 10 or more total read counts across samples keep &lt;- rowSums(counts(dds)) &gt;= 10 message(str_glue(&quot;Keeping {sum(keep)} genes.&quot;)) ## Keeping 21485 genes. dds &lt;- dds[keep, ] 4.4.5 Different normalization approaches for different biases Types of biases in RNA-seq 4.4.6 Run the DE workflow The DESeq function is a convenience function from DESeq2 that estimates size factors (normalization) and fits negative binomial GLMs. dds &lt;- DESeq(dds) ## estimating size factors ## estimating dispersions ## gene-wise dispersion estimates ## mean-dispersion relationship ## final dispersion estimates ## fitting model and testing message(paste0(&quot;Coefficient names are: &quot;, paste(resultsNames(dds), collapse = &quot; &quot;))) ## Coefficient names are: Intercept group_untrt_vs_trt After the models are fitted, we can test specific pairs of groups for differential expression. For DESeq2, it is recommended to provide the significance cutoff that you wish to use as it affects the multiple testing correction procedure (see docs). contrast &lt;- c(&quot;group&quot;, &quot;trt&quot;, &quot;untrt&quot;) fdr_cutoff &lt;- 0.1 res &lt;- results(dds, contrast=contrast, alpha=fdr_cutoff) res &lt;- res[order(res$pvalue), ] 4.4.7 Summarize DE results df &lt;- as.data.frame(res) data.frame( UP=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &gt; 0, na.rm = TRUE), DWN=sum(df$padj &lt;= fdr_cutoff &amp; df$log2FoldChange &lt; 0, na.rm = TRUE), Tested=sum(!is.na(df$padj)) ) ## UP DWN Tested ## 1 1872 1481 17272 4.4.8 Shrink log fold changes for lowly expressed genes This step does not affect the identification of DE genes, but it can be useful to perform this to obtain more reliable estimates of the log fold changes for visualizations or for ranking genes (e.g. GSEA). lfc_shrink &lt;- lfcShrink(dds, contrast=contrast, type=&quot;ashr&quot;) ## using &#39;ashr&#39; for LFC shrinkage. If used in published research, please cite: ## Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2. ## https://doi.org/10.1093/biostatistics/kxw041 lfc_shrink &lt;- lfc_shrink[order(lfc_shrink$pvalue), ] DESeq2::plotMA(res, main=&quot;Default LFC&quot;) DESeq2::plotMA(lfc_shrink, main=&quot;Shrunken LFC&quot;) 4.4.9 Output DE results Here, we merge the different gene name columns to the DE results and output to a tab-delimited file, which can be opened in Excel for manual perusal. df &lt;- cbind(as.data.frame(rowData(dds)[rownames(lfc_shrink), 1:4]), as.data.frame(lfc_shrink)) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(df, file.path(outdir, &quot;de_res.tsv&quot;)) 4.4.10 Look for specific genes We know certain genes should be differentially expressed based on the paper that this dataset came from. We can check that these genes were significantly DE in our analysis. Likewise, this would be a good time to check for knocked down, knocked out etc genes if such prior knowledge is available, though that is not always the case. df %&gt;% dplyr::filter(Symbol %in% c(&quot;DUSP1&quot;, &quot;KLF15&quot;, &quot;CRISPLD2&quot;)) ## ens_gene Symbol Uniq_syms entrez ## 1 ENSG00000120129.6 DUSP1 DUSP1 1843 ## 2 ENSG00000163884.4 KLF15 KLF15 28999 ## 3 ENSG00000103196.12 CRISPLD2 CRISPLD2 83716 ## Gene_name baseMean ## 1 dual specificity phosphatase 1 3357.1543 ## 2 KLF transcription factor 15 551.1765 ## 3 cysteine rich secretory protein LCCL domain containing 2 2875.4571 ## log2FoldChange lfcSE pvalue padj ## 1 2.899715 0.1982447 9.251009e-50 3.195669e-46 ## 2 4.325184 0.4142733 2.361153e-28 1.568532e-25 ## 3 2.618796 0.2590196 2.407565e-25 1.144831e-22 4.4.11 Output tables with raw counts Some folks also find it useful to have tables of the raw counts or the normalized counts. The raw counts can be extracted from the DESeq2 object using either assay() or counts(). df &lt;- cbind(as.data.frame(rowData(dds)[, 1:4]), assay(dds, &quot;counts&quot;)) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(df, file.path(outdir, &quot;counts.tsv&quot;)) 4.4.12 Output tables with log2 normalized counts For the log2 normalized counts, we commonly use the variance stabilized transformation (VST). These values can be used for heatmaps, clustering or other downstream applications. vsd &lt;- vst(dds, blind=FALSE) vst_df &lt;- as.data.frame(cbind(rowData(vsd)[, 1:4], assay(vsd))) %&gt;% tibble::rownames_to_column(&quot;ens_gene&quot;) write_tsv(vst_df, file.path(outdir, &quot;vst.tsv&quot;)) 4.5 Some common plots for DEG analysis 4.5.1 Volcano plot make_volcano &lt;- function(df, pval_nm, pval_cutoff=0.1){ # remove genes with NA for pvalue df &lt;- df[which(!is.na(df[[pval_nm]])), ] # add gene names df &lt;- cbind(df, rowData(dds)[rownames(df), 1:4]) top_genes &lt;- df %&gt;% dplyr::arrange(desc(abs(df$log2FoldChange))) %&gt;% dplyr::filter(row_number() &lt;= 10) %&gt;% rownames() df$Sig &lt;- ifelse(df$padj &lt;= pval_cutoff, &quot;Sig&quot;, &quot;NS&quot;) df[[pval_nm]] &lt;- -log10(df[[pval_nm]]) ggplot(df, aes_string(x=&quot;log2FoldChange&quot;, y=pval_nm)) + geom_point(aes(color=Sig), size=0.6) + scale_color_manual(values=c(&quot;black&quot;, &quot;salmon&quot;)) + theme_bw() + ylab(str_glue(&quot;-log10(&quot;, pval_nm,&quot;)&quot;)) + geom_text_repel(data=df[top_genes, ], aes(label=Uniq_syms), max.overlaps=Inf, min.segment.length = 0) } make_volcano(as.data.frame(lfc_shrink), pval_nm=&quot;padj&quot;, pval_cutoff=fdr_cutoff) ## Warning: `aes_string()` was deprecated in ggplot2 3.0.0. ## ℹ Please use tidy evaluation idioms with `aes()`. ## ℹ See also `vignette(&quot;ggplot2-in-packages&quot;)` for more information. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. 4.5.2 Heatmap top_genes &lt;- rownames(res)[1:20] top_se &lt;- se[top_genes, ] mat &lt;- assay(top_se, &quot;vst&quot;) mat &lt;- t(scale(t(mat), scale=FALSE, center = TRUE)) # column annot ht_col_annot &lt;- as.data.frame(colData(top_se)[, &quot;group&quot;, drop=FALSE]) group_lvls &lt;- unique(ht_col_annot$group) ht_col_colors &lt;- list(group=setNames(c(&quot;#440154FF&quot;,&quot;#2A788EFF&quot;), nm=group_lvls)) Heatmap(mat, name = &quot;Mean-centered&quot;, cluster_columns = FALSE, row_labels=rowData(top_se)$Uniq_syms, show_column_names = FALSE, top_annotation=HeatmapAnnotation(df=ht_col_annot, col=ht_col_colors), column_title = &quot;Top DE genes&quot;, row_title = paste0(nrow(mat), &quot; genes&quot;) ) 4.5.3 P value distribution Ideally, we will see an anti-conservative (if there are many DE genes) or uniform pattern (not many DE genes). See here for more details about how to interpret these. ggplot(data = as.data.frame(lfc_shrink) %&gt;% dplyr::filter(!is.na(pvalue)), aes(x = pvalue)) + geom_histogram(color = &quot;black&quot;, fill = &quot;gray55&quot;, breaks = seq(0, 1, 0.05)) + theme_bw() + theme(plot.title=element_text(size=10)) "],["pathway-enrichment-and-experimental-design.html", "Part 5 Pathway, enrichment, and experimental design 5.1 Downstream of DE gene analysis", " Part 5 Pathway, enrichment, and experimental design 5.1 Downstream of DE gene analysis 5.1.1 Copy the project directory You will make your own directory, and copy the directory containing data and R code into your own. cd /varidata/researchtemp/hpctmp/BBC_workshop_June2023_III/ mkdir &lt;username&gt; cd &lt;username&gt; pwd ## make sure you are in your dir cp -r ../workshopIII_files . cd workshopIII_files ls "],["appendices.html", "Part 6 Appendices 6.1 Workshop Powerpoint files 6.2 Local access of files on the HPC 6.3 Bash cheatsheet", " Part 6 Appendices 6.1 Workshop Powerpoint files June 8, 2023; Summer workshop I 6.2 Local access of files on the HPC Mac: 1. Click Finder &gt; “Go” in task bar &gt; “Connect to Server” in the pulldown menu. 2. Type smb://pn.vai.org and click “Connect”. 3. Select ‘projects’ and ‘researchtemp’. Click “OK”. 4. You can now navigate using Finder, or type ls /Volumes/projects/ or ls /Volumes/researchtemp/ in the Terminal. Windows: * In File Explorer, type \\\\pn.vai.org\\ and hit Enter. 6.3 Bash cheatsheet Name Command Line Description Example Print Working Directory pwd Displays the current working directory [username\\@submit002 ~]$ pwd Result:/home/username List ls Lists the files and directories in the current directory [username\\@submit002 ~]$ ls Result: It returns empty after the $ symbol since nothing has been created. List More Detail ls -lht Display more details about the file [username\\@submit002 ~]$ ls -lht Result: Display file detail in the current director Make Directory mkdir Creates a new directory [username\\@submit002 ~]$ mkdir hpc_mini_workshop Result: A hpc_mini_workshop folder is created. Move mv Moves or renames files or directories [username\\@submit002 ~]$ mv hpc_mini_workshop workshopTraining Result: Now the hpc_mini_workshop directory is called workshopTraining Change Directory cd Change to an existing directory [username\\@submit002 ~]$ cd workshopTraining Result: [username@submit002 workshopTraining]$ Notice ~ was in the home directory, now in the workshopTraining directory. Remove rm Deletes files and directories [username\\@submit002 ~]$ rm -r TaskProject *Note: -r means directory Result: TaskProject is deleted Copy cp Copies files or directories [username\\@submit002 ~]$ cp -r Task1 Project Result: Task1 directory has moved to the Project directory. Search for File find Search for files and directories based on various criteria like name, size, and modification time [username\\@submit002 ~]$ find Project Result: Task1 will appear within the Project directory Project Project/Task1 Head head Display at the beginning of a file [username\\@submit002 ~]$ head -n5 file_name Result: It will display the first 5 lines from the beginning of the file_name. Tail tail Display at the end of a file [username\\@submit002 ~]$ tail -n5 file_name Result: It will display the last 5 lines from the end of the file_name Less less Load the necessary portion of a file [username\\@submit002 ~]$ less file.txt Result: The user is able to view a portion of the file.txt. More more Load the entire file [username\\@submit002 ~]$ more file.txt Result: The user is able to view the entire file.txt. Quit q Stop viewing the current file quit viewing the current file Concatenate cat Display the contents of a file [username\\@submit002 ~]$ cat file.txt Result: Display the contents of file.txt Search for Text grep Search for a specific pattern of text within files [username\\@submit002 ~]$ grep “GCGGA” sequence_file.fastq Result: Display any GCGGA pattern in sequence_file.fastq Word, Line, and Character Count wc Display the number of words, lines, and characters in a file [username\\@submit002 ~]$ wc file.txt Result: Display the number of words, lines, and characters in the file.txt. Touch touch Create a new empty file [username\\@submit002 ~]$ touch exampleFile.txt Result: The command line will display file details in the current directory "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
